---
created: 2023-01-30T16:26:01 (UTC -05:00)
tags: []
source: https://stable-diffusion-art.com/outpainting/
author: 
---

# How to Use Outpainting to Extend Images - Stable Diffusion Art

> ## Excerpt
> Do you know Stable Diffusion can be used to extend an image in any directions? The function is called outpainting. It can generate coherent background that

---

Do you know Stable Diffusion can be used to extend an image in any directions? The function is called **outpainting**. It can generate coherent background that was originally out of frame. In this article, we will walk through how to do it step-by-step in AUTOMATIC1111 GUI. I will also introduce other excellent outpainting models as alternatives.

Contents \[[hide](https://stable-diffusion-art.com/outpainting/#)\]

- [Software needed](https://stable-diffusion-art.com/outpainting/#Software_needed)
- [Step-by-step guide](https://stable-diffusion-art.com/outpainting/#Step-by-step_guide)
    - [Upload image to AUTOMATIC1111](https://stable-diffusion-art.com/outpainting/#Upload_image_to_AUTOMATIC1111)
    - [Adjust parameters for outpainting](https://stable-diffusion-art.com/outpainting/#Adjust_parameters_for_outpainting)
    - [Enable outpainting script](https://stable-diffusion-art.com/outpainting/#Enable_outpainting_script)
- [Center an image](https://stable-diffusion-art.com/outpainting/#Center_an_image)
- [Convert to landscape size](https://stable-diffusion-art.com/outpainting/#Convert_to_landscape_size)
- [Fix details with inpainting](https://stable-diffusion-art.com/outpainting/#Fix_details_with_inpainting)
- [Outpainting complex scenes](https://stable-diffusion-art.com/outpainting/#Outpainting_complex_scenes)
    - [Failure example of Stable Diffusion outpainting](https://stable-diffusion-art.com/outpainting/#Failure_example_of_Stable_Diffusion_outpainting)
    - [MAT outpainting](https://stable-diffusion-art.com/outpainting/#MAT_outpainting)
- [Other outpainting options](https://stable-diffusion-art.com/outpainting/#Other_outpainting_options)
    - [Stable Diffusion Infinity](https://stable-diffusion-art.com/outpainting/#Stable_Diffusion_Infinity)

## Software Needed

We will use [AUTOMATIC1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui), a popular and full-feature Stable Diffusion GUI, in this guide. We will use the 1-click launch Colab Notebook in the [Quick Start Guide](https://andrewongai.gumroad.com/l/stable_diffusion_quick_start). See [instructions](https://stable-diffusion-art.com/automatic1111-colab/) to use. You can also install this GUI on [Windows](https://stable-diffusion-art.com/install-windows/) and [Mac](https://stable-diffusion-art.com/install-mac/).

When launching the notebook, make sure to select F222 model which will be used in this tutorial.

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/image-63.png?resize=480%2C247&ssl=1)

## Step-by-step Guide

The first step is to get your image ready. I will use this image generated by Stable Diffusion. In this tutorial, we will use the following image as the starting point. We will use outpainting to **center the image** and t**urn it to landscape size**.

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/01316-2271173312-A-digital-artstationd-dystopia-art-looking-side-way-fantasy_1.5-painting-of-Ana-de-Armas_-emma-watson_-0.8-in-street_1.5.png?resize=384%2C576&ssl=1)

Starting image for outpainting.

You can download this image using the button below to follow the tutorial.

### Upload Image to AUTOMATIC1111

If the image was generated by AUTOMATIC1111 GUI, the prompts and other generation parameters were written into PNG file”s meta data.

In AUTOMATIC1111 GUI, Go to **PNG Info** tab. Drag and drop the image from your local storage to the canvas area. The generation parameters should appear on the right.

Press **Send to img2img** to send this image and parameters for outpainting. The image and prompt should appear in the **img2img** sub-tab of the **img2img** tab.

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/image-55.png?resize=480%2C156&ssl=1)

Use PNG Info tab to extract generation parameters.

If your starting image is not created by AUTOMATIC1111 GUI, simply proceed to the **img2img** tab. Upload the image to the **img2img** canvas. You will need to write a prompt to accurately describe the image and style. (You may have the prompt automatically generated by clicking “Interrogate CLIP”. But it is not very good in my opinion.)

### Adjust Parameters for Outpainting

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/image-56.png?resize=480%2C346&ssl=1)

First you will need to select an appropriate **model** for outpainting. For consistency in style, you should use the same model that generates the image. For example, I used [F222](https://stable-diffusion-art.com/models/#F222) model so I will use the same model for outpainting.

If you used the base model [v1.4](https://stable-diffusion-art.com/models/#Stable_diffusion_v14) and [v1.5](https://stable-diffusion-art.com/models/#Stable_diffusion_v15), or you are using a photograph, you can also use the [v1 inpainting model](https://stable-diffusion-art.com/inpainting_basics/#Use_an_inpainting_model_optional). It is supposed to give better results. Although I have no problem without using it.

The **image size** should have automatically set correctly if you used **PNG Info**. For a custom image, you should set the shorter side to the native resolution of the model, e.g. 512 px for v1 models. The longer side should be adjusted accordingly to maintain the aspect ratio.

Set **resize mode** to **crop and resize** so that the aspect ratio won’t change.

Set **seed** to -1 to get a different result each time.

[Denoising strength](https://stable-diffusion-art.com/inpainting_basics/#Denoising_strength) will be the knot you will have a lot of fun to play with… for now let’s set it to 0.6.

You can use your standard text-to-image setting for the rest. For completeness, here are what I use

- Sampling method: DPM++ 2M Karras
- Sampling Steps: 30
- Batch size: 4

This is my setting section look like:

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/image-57.png?resize=480%2C312&ssl=1)

### Enable Outpainting Script

Scroll down and you should see a **Script** drop box. There are two options for outpainting: (1) outpainting mk2 and (2) poor man’s outpainting. Outpainting mk2 doesn’t work very well. **Choose Poor man’s outpainting**.

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/image-58.png?resize=480%2C199&ssl=1)

You can leave **Pixels to expand** at 128 pixels. Pick **fill** for **masked** **content**. It will use the average color of the image to fill in the expanded area before outpainting.

It is best to outpaint one direction at a time. I pick **right** for **outpaint** **direction** for this image.

I am reusing the original **prompt**.

Press **Generate** and you are in business! Regenerate as many time as needed until you see an image you like.

Increase denoising strength to change more. Decrease denoising strength to change less. It is that simple.

## Center an Image

This is what got. She is no longer on the right of the photo but is dead center. The expanded pixels are visually consistent with the rest of the image. I am pleased!

![Outpainting to center an image.](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/01321-2200156095-A-digital-artstationd-dystopia-art-looking-side-way-fantasy_1.5-painting-of-Ana-de-Armas_-emma-watson_-0.8-in-street_1.5.png?resize=480%2C576&ssl=1)

Outpainting was used to expand the right hand side.

Once you are happy with one side, you can hit **Send to img2img** under the result canvas to iterate the process.

## Convert to Landscape Size

Let’s extend the left and right sides multiple times so that the portrait-sized image becomes landscape. This can change the perception of the image completely. Now it is not a close-up of the subject. The expansive dystopia city background creates a great contrast and tells a good story.

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/01327-3797006489-A-digital-artstationd-dystopia-art-looking-side-way-fantasy_1.5-painting-of-Ana-de-Armas_-emma-watson_-0.8-in-street_1.5.png?resize=480%2C305&ssl=1)

## Fix Details with Inpainting

You don’t need to be too hung up on the little details of the extended part because you can always regenerate any areas later with [inpainting](https://stable-diffusion-art.com/inpainting_basics/). Below I will show you how to regenerate the whole right hand side.

First, press **Send to inpainting** to send your newly generated image to the inpainting tab. Make sure to select the **Inpaint** **tab**. Use the paintbrush tool to create a **mask** on the area you want to regenerate.

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/image-59.png?resize=480%2C366&ssl=1)

The settings I used are

- **Mask mode**: Inpaint masked
- **Inpaint area**: Only masked
- **Only masked padding**, pixels: 36-72 (adjust as need)
- **Script**: None (Don’t forget the turn off the outpainting script!)
- **Denoising strength**: 0.6-0.9. You will want to look at the result and adjust this. Increase to change more.
- **Batch size**: 2-4. Generate multiple images at a time for comparison.
- **Seed**: -1 (random)
- Masked content: original or fill. (Fill will use the average color under the mask as the initial value)

Below is a screenshot of my inpainting settings. See [Inpainting Guide](https://stable-diffusion-art.com/inpainting_basics/) for more detailed explanations.

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/image-60.png?resize=480%2C415&ssl=1)

Inpainting setting.

After a few rounds of inpainting, this is my final image in landscape size.

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/01352-2629874737-A-digital-artstationd-dystopia-art-looking-side-way-fantasy_1.5-painting-of-Ana-de-Armas_-emma-watson_-0.8-in-street_1.5.png?resize=480%2C305&ssl=1)

## Outpainting Complex Scenes

The above Stable Diffusion method works well with simple background. It will struggle with complex scenes. The reason is that the outpainting method only considers a small area of image adjacent to the outpainted area. To extend a complex scene, long range information need to be accounted for.

It is not Stable Diffusion (Sorry Stable Diffusion purist!), but there’s an outstanding inpainting/outpainting method available called [MAT](https://github.com/fenglinglwb/MAT) (Mask-Aware Transformer). It is a GAN model designed to account for long range information when making up parts of an image.

### Failure Example of Stable Diffusion Outpainting

To illustrate the importance of modeling long range information, let’s outpaint the following complex street scene.

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/photo-1673946723153-4994870b64e1.jpeg?resize=480%2C720&ssl=1)

Using the above method to expand the **right hand side**, we get this image:

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/01574-1905047647-Japanese-street-next-to-a-train-track-at-night-with-signs-above-them-that-read-by-Liam-Wong.jpg?resize=480%2C689&ssl=1)

The extended part looks ok on its own but is not coherent to the rest of the image as a whole.

### MAT Outpainting

MAT outpainting is not only faster, but gives better results. See the image below extended by MAT. It’s not perfect, but much better.

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/MAT-outpaint-scale-1.png?resize=480%2C480&ssl=1)

Go to [Stable Diffusion Mat Outpainting](https://huggingface.co/spaces/Rothfeld/stable-diffusion-mat-outpainting-primer) to use MAT. The GUI only allows you to generate a square image. You can generate a larger square image and crop it to landscape size. **Scale** is the scaling applied on the uploaded image before outpainting. I set scale to 1 in the above image and set the output size to 768 so that it outpaints a 512×768 image to 768×768, extending the left and right sides.

MAT also worked quite well with our example. Below is the image outpainted laterally.

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/image-61.png?resize=480%2C480&ssl=1)

## Other Outpainting Options

If you don’t want to use AUTOMATIC1111 for whatever reason, this section is for you.

### Stable Diffusion Infinity

[Stable Diffusion Infinity](https://huggingface.co/spaces/lnyan/stablediffusion-infinity) is a nice graphical outpainting user interface. The Huggingface demo is free to use. It can run pretty fast if no one else is using. You can also launch a colab notebook to run your own instance.

The interface let you outpaint one tile at a time. You will need to write a prompt for each tile. Each tile should have a small overlap with the existing image.

![](https://i0.wp.com/stable-diffusion-art.com/wp-content/uploads/2023/01/image-62.png?resize=480%2C249&ssl=1)

There’s a demo video in the [Github page](https://github.com/lkwq007/stablediffusion-infinity) to show you how to use it.

---

#AI #article
