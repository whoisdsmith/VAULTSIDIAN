
- https://twitter.com/emollick/status/1610261628607512576
- https://arxiv.org/pdf/2212.13138.pdf
	- Large Language Models Encode Clinical Knowledge, Google/DeepMind
	- we present MultiMedQA, a benchmark combining six existing open question answering datasets spanning professional medical exams, research, and consumer queries; and HealthSearchQA, a new free-response dataset of medical questions searched online
	- Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA, MedMCQA, PubMedQA, MMLU clinical topics), including 67.6% accuracy on MedQA (US Medical License Exam questions), surpassing prior state-of-the-art by over 17%. However, human evaluation reveals key gaps in Flan-PaLM responses. To resolve this we introduce instruction prompt tuning, a parameter-efficient approach for aligning LLMs to new domains using a few exemplars. The resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians.
- pubmed gpt https://www.mosaicml.com/blog/introducing-pubmed-gpt
- Medical exams https://twitter.com/pythonprimes/status/1601785791931240449?s=20
	- passed USMLE https://twitter.com/noor_siddiqui_/status/1617194845810077697?s=20
	- another USMLE research https://twitter.com/valentinlievin/status/1605965336179658766
	- Today, it takes 4 years of med school and 2+ years of clinical rotations to pass. It tests ambiguous scenarios & closely-related differential diagnoses